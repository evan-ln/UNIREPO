---
title: "Music Data Dashboard"
output: 
  flexdashboard::flex_dashboard:
    theme: "cosmo"
date: "2025-02-28"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(plotly)
library(readr)
library(dplyr)
library(tuneR)
library(seewave)
library(av)

# Install required packages (if not already installed)
if (!requireNamespace("tuneR", quietly = TRUE)) install.packages("tuneR")
if (!requireNamespace("seewave", quietly = TRUE)) install.packages("seewave")
if (!requireNamespace("av", quietly = TRUE)) install.packages("av")

# Convert MP3 to WAV
av_audio_convert("evan-l-1.mp3", "evan-l-1.wav", format = "wav")
av_audio_convert("evan-l-2.mp3", "evan-l-2.wav", format = "wav")

# Load the dataset
compmus_data <- read_csv("compmus2025.csv")

# Define my tracks
my_tracks <- c("evan-l-1", "evan-l-2")
```


Dash Version 2.0

---

# Chromagram

## Chromagrams for own tracks

**!!! I currently keep having issues with my chromagrams not loading (though they do show in R), so it may be that they don't show up yet. Trying to fix this ASAP.**


Chromagrams capture the harmonic content by showing how energy is distributed across the 12 pitch classes over time.

```{r chromagrams, echo=FALSE}
#currently has issues loading.. why?
plot_chromagram <- function(file) {
  wave <- readWave(file)
  dev.new()  # To open a new graphic
  spectro(wave, wl = 1024, ovlp = 75, collevels = seq(-50, 0, 5), main = paste("Chromagram -", file))
}


par(mfrow = c(2,1))
plot_chromagram("evan-l-1.wav")
plot_chromagram("evan-l-2.wav")
```
- **Evan-l-1.wav - Ambient **
  - The energy is mainly in the lower frequency range, below ~5 kHz
  - The overall amplitude is low, this reflects the quiet ambient sounds
  - The minimal structure suggests an ambient or instrumental track

- **Evan-l-2.wav - Breakbeat **
  - Covers a much wider frequency range, reaching beyond 10 kHz, with distinct variations in energy
  - Brighter colors indicate stronger amplitude, due to the track being comparatively dynamic
  - The structure implies prominent rhythmic and melodic elements, as is the case with my breakbeat track

---


```{r self_similarity, echo=FALSE}
compute_ssm <- function(file, feature = "chroma") {
  wave <- readWave(file)
  
  # Extract the signal
  signal <- wave@left 
  sr <- wave@samp.rate  # Get sample rate
  
  if (feature == "chroma") {
    chroma <- melfcc(wave, numcep = 12)  # No `$cep`
    dist_matrix <- as.matrix(dist(t(chroma)))  # Convert to self-similarity matrix
  } else if (feature == "timbre") {
    timbre <- melfcc(wave, numcep = 20)
    dist_matrix <- as.matrix(dist(t(timbre)))
  }
  
  return(dist_matrix)
}

ssm_chroma_1 <- compute_ssm("evan-l-1.wav", feature = "chroma")
ssm_timbre_1 <- compute_ssm("evan-l-1.wav", feature = "timbre")
ssm_chroma_2 <- compute_ssm("evan-l-2.wav", feature = "chroma")
ssm_timbre_2 <- compute_ssm("evan-l-2.wav", feature = "timbre")

par(mfrow = c(2,2))
image(ssm_chroma_1, main = "Chroma SSM - Evan-l-1.wav", col = gray.colors(100))
image(ssm_timbre_1, main = "Timbre SSM - Evan-l-1.wav", col = gray.colors(100))
image(ssm_chroma_2, main = "Chroma SSM - Evan-l-2.wav", col = gray.colors(100))
image(ssm_timbre_2, main = "Timbre SSM - Evan-l-2.wav", col = gray.colors(100))
```

## SSMs


- **Evan-l-1.wav - Ambient**
  - The chroma-SSM shows some variation, but overall pretty uniform and repetitive
  - The timbre-SSM is mostly smooth and table

- **Evan-l-2.wav - Breakbeat**
  - The chroma-SSM has more distinct patterns, like a checkerboard. The song has stronger harmonic changes with varied chord progressions.
  - The timbre-SSM shows greater shifts in instruments or timbres


---

# AI-Generated Tracks

These tracks were created using **Stableaudio AI** ([Stableaudio](https://stableaudio.com/generate)). I took inspiration from genre tags on **RateYourMusic** and carefully crafted prompts using detailed descriptors to shape the sound. After generating the tracks, I simply downloaded the MP3 files.

**Track 1: Meditative Ambient Soundscape**

**Style:** Ambient, Post-Rock, Cinematic  
**Length:** 2 minutes  
**Goal:** A calm, meditative ambient with minimal instrumentation.  

**Tags Used:**  
Ambient, Post-Rock, Cinematic, Ethereal, Soothing, Meditative, Minimalist, Warm Subtle Bass, Deep Drones, Airy Pads, Textures, Analog Synths, Field Recordings, Wind Sounds, Reverb, **60 BPM**
---

**Track 2: Energetic Breakbeat Rave**

**Style:** Breakbeat, Acid Breaks, 90s Rave  
**Length:** 2 minutes  
**Goal:** A high-energy, chaotic breakbeat track.  

**Tags Used:**  
Breakbeat, Acid Breaks, 90s Rave, Energetic, Raw, Funky, Chaotic, Breakbeats, Deep Bass, Distorted 808, Acid Bass, Filtered Chords, Reversed Pads, Vocal Chops, **135 BPM**

---

**Track Creation**

1. **Prompt Design:**  
   - Used RateYourMusic to explore fitting **genre tags**.  
   - Structured prompts with **specific instruments, moods, and BPM** to guide the AI.  
2. **Generation:**  
   - Entered prompts into **Stableaudio AI**.  
   - Experimented with variations before selecting the best versions.  
3. **Finalization:**  
   - Downloaded the **MP3 files** and ensured they matched my vision.  =

---

# Visualization

Here's a scatterplot of the Danceability compared to the Tempo of the tracks. My track 1 (ambient) is marked red, track 2 (breakbeat) is blue.

```{r danceability_plot, echo=FALSE, fig.width=6, fig.height=4}
dance_plot <- ggplot(compmus_data, aes(x = danceability, y = tempo, color = danceability, text = filename)) +
  geom_point(alpha = 0.6, size = 2) +  
  geom_point(data = compmus_data %>% filter(filename == "evan-l-1"), 
             aes(x = danceability, y = tempo, text = filename), color = "red", size = 2.5) +
  geom_point(data = compmus_data %>% filter(filename == "evan-l-2"), 
             aes(x = danceability, y = tempo, text = filename), color = "blue", size = 2.5) +
  labs(title = "Danceability vs. Tempo",
       x = "Danceability",
       y = "Tempo",
       color = "Danceability") +
  theme_classic()

# Adjust plot size + hover tooltips show song titles
ggplotly(dance_plot, tooltip = "text")
```

---

# Final Thoughts

There appears to be no set correlation between the danceability and tempo of the tracks. However, an interesting pattern emerges: there are two clusters—one with low danceability, and another with high danceability, while the tempo does not differ much.

Regarding my own tracks:

- The **calm ambient track** has an average tempo and low danceability.
- The **breakbeat song** has an average tempo but high danceability.

One particularly surprising observation is how the AI interpreted the second song’s tempo. While I set it to **135 BPM**, it was classified as **93 BPM**. This suggests that the AI might have emphasized a different rhythmic structure or half-time feel in its classification.
